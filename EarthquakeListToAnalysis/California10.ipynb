{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from config import email, key\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [\"ci37908735\",\"nc72737985\",\"ci37374687\",\"nc72282711\",\"ci15200401\",\"ci15199681\",\"ci10736069\",\n",
    "          \"ci14408052\",\"ci14383980\",\"nc40216664\",\"nc40204628\"]\n",
    "\n",
    "i=0\n",
    "\n",
    "earthquakes_list = []\n",
    "\n",
    "for event in events:\n",
    "    base_url = \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson\"\n",
    "    times_url = \"&starttime=1990-01-01&endtime=2019-06-15\"\n",
    "    magnitude_url =\"&minmagnitude=5.0\"\n",
    "    #geometry_url = \"&minlatitude=32.43&maxlatitude=42.05&minlongitude=-124.28&maxlongitude=-114.11\"\n",
    "    eventid_url = f\"&eventid={event}\"\n",
    "    \n",
    "    search = requests.get(base_url + times_url + magnitude_url + eventid_url)\n",
    "    \n",
    "    response = search.json()\n",
    "\n",
    "    identifier = response['id']\n",
    "    mag = response['properties']['mag']\n",
    "    url = response['properties']['url']\n",
    "    epochtime = response['properties']['time']\n",
    "    four_weeks_before = epochtime - 2419200000\n",
    "    four_weeks_after = epochtime + 2419200000\n",
    "    event_date= time.strftime('%Y%m%d',  time.gmtime(epochtime/1000))\n",
    "    month_before= time.strftime('%Y%m%d',  time.gmtime(four_weeks_before/1000))\n",
    "    month_after = time.strftime('%Y%m%d',  time.gmtime(four_weeks_after/1000))\n",
    "    converted_time = time.strftime('%H:%M:%S',  time.gmtime(epochtime/1000))\n",
    "    timezone=response['properties']['tz']\n",
    "    place = response['properties']['place']\n",
    "    significance=response['properties']['sig']\n",
    "    lon = response['geometry']['coordinates'][0]\n",
    "    lat = response['geometry']['coordinates'][1]\n",
    "    depth = response['geometry']['coordinates'][2]\n",
    "    record_dict = {\"Identifier\":identifier, \"Location\":place, \"Magnitude\":mag, \"Event Date\":event_date,\n",
    "                   \"Month Before\":month_before, \"Month After\":month_after, \"Time\":converted_time,\"Time Zone\":timezone, \n",
    "                   \"Significance\":significance, \"Lat\":lat, \"Lon\":lon, \"Depth\":depth, \"Epoch Time\":epochtime}\n",
    "    earthquakes_list.append(record_dict)\n",
    "        \n",
    "    i += 1\n",
    "          \n",
    "earthquakes_df = pd.DataFrame(earthquakes_list)\n",
    "\n",
    "earthquakes_df = earthquakes_df[~earthquakes_df[\"Location\"].str.contains(\"Mexico\")]\n",
    "\n",
    "earthquakes_df = earthquakes_df[~earthquakes_df[\"Location\"].str.contains(\"MX\")]\n",
    "\n",
    "earthquakes_df = earthquakes_df[~earthquakes_df[\"Location\"].str.contains(\"Nevada\")]\n",
    "\n",
    "earthquakes_df = earthquakes_df[~earthquakes_df[\"Location\"].str.contains(\"NV\")].reset_index()\n",
    "\n",
    "earthquakes_df = earthquakes_df.fillna(value=\"\")\n",
    "\n",
    "earthquakes_abbrev =earthquakes_df[['Location', 'Event Date', 'Magnitude']]\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "earthquakes_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_df.to_csv(\"earthquake_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "earthquake = 0\n",
    "record_list = []\n",
    "\n",
    "for rows in earthquakes_df.iterrows():\n",
    "\n",
    "    # base_url finds air quality readings by Box\n",
    "\n",
    "    base_url = \"https://aqs.epa.gov/data/api/dailyData/byBox?\"\n",
    "\n",
    "    #parameters for byBox for CRITERIA Pollutants \n",
    "    #42401=\"Sulfur Dioxide\" \n",
    "    #42602=\"Nitrogen Dioxide\"\n",
    "    #42201=\"Ozone\"\n",
    "    #42101 = \"Carbon Monoxide\"\n",
    "\n",
    "    begin = earthquakes_df.iloc[earthquake, 5]\n",
    "    end = earthquakes_df.iloc[earthquake, 6]\n",
    "    minlat=earthquakes_df.iloc[earthquake,10]-1\n",
    "    maxlat=earthquakes_df.iloc[earthquake,10]+1\n",
    "    minlon=earthquakes_df.iloc[earthquake,11]-1\n",
    "    maxlon=earthquakes_df.iloc[earthquake,11]+1\n",
    "    earthquake_location=earthquakes_df.iloc[earthquake,2]\n",
    "    event_date =earthquakes_df.iloc[earthquake, 4]\n",
    "    \n",
    "    param_url = f\"param=42401,42602,44201,42101,81102,88101\"\n",
    "    date_range_url = f\"&bdate={begin}&edate={end}\"\n",
    "    geometry_url = f\"&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}\"\n",
    "\n",
    "    url = (base_url + param_url + \"&email=\" + email + \"&key=\" + key + date_range_url + geometry_url)\n",
    "    \n",
    "    search = requests.get(url)\n",
    "    responses = search.json()\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for record in responses['Data']:\n",
    "        site = responses['Data'][i]['local_site_name']\n",
    "        station = responses['Data'][i]['site_number']\n",
    "        parameter = responses['Data'][i]['parameter']\n",
    "        date = responses['Data'][i]['date_local']\n",
    "        measurement = responses['Data'][i]['arithmetic_mean']\n",
    "        measurement_unit = responses['Data'][i]['units_of_measure']\n",
    "        event_type=responses['Data'][i][\"event_type\"]\n",
    "        lon = responses['Data'][i]['longitude']\n",
    "        lat = responses['Data'][i]['latitude']\n",
    "        earthquake_id = earthquakes_df.iloc[earthquake, 1]\n",
    "        record_dict = {\"Earthquake ID\":earthquake_id,\"Parameter\":parameter,\"Date\":date,\"Station\":station,\"Site\":site, \n",
    "                       \"Lat\":lat,\"Lon\":lon, \"Measurement\":measurement, \"Unit\":measurement_unit,\"Event Type\":event_type}\n",
    "        record_list.append(record_dict)\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    earthquake += 1    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_df = pd.DataFrame(record_list)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "record_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_summary = record_df[['Parameter', \"Measurement\", \"Unit\"]]\n",
    "param_min = param_summary.groupby(['Parameter']).min()\n",
    "param_max = param_summary.groupby(['Parameter']).max()\n",
    "param_mean = param_summary.groupby(['Parameter']).mean()\n",
    "param_median = param_summary.groupby(['Parameter']).median()\n",
    "param_count = param_summary.groupby(['Parameter']).count()\n",
    "stats = pd.merge(param_min, param_max, on = \"Parameter\")\n",
    "stats = stats.rename(columns = {\"Measurement_x\":\"Min\", \"Measurement_y\":\"Max\",\"Unit_x\":\"Unit\"})\n",
    "stats = stats.drop(columns = \"Unit_y\")\n",
    "stats = pd.merge(stats, param_mean, on= 'Parameter')\n",
    "stats = stats.rename(columns ={'Measurement':\"Mean\"})\n",
    "stats = pd.merge(stats, param_median, on = 'Parameter')\n",
    "stats = stats.rename(columns ={'Measurement':'Median'})\n",
    "stats = pd.merge(stats, param_count, on = 'Parameter')\n",
    "stats = stats.rename(columns = {'Measurement':'Count','Unit_x':\"Unit\"})\n",
    "stats = stats.drop(columns = \"Unit_y\")\n",
    "stats = stats[['Unit','Count','Min','Max','Mean','Median']]\n",
    "stats.to_csv('Stats_California11.csv')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish dataframe for each earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "events = [\"ci37908735\",\"nc72737985\",\"ci37374687\",\"nc72282711\",\"ci15200401\",\"ci15199681\",\"ci10736069\",\n",
    "          \"ci14408052\",\"ci14383980\",\"nc40216664\",\"nc40204628\"]\n",
    "\n",
    "df_eq0 = record_df[record_df['Earthquake ID']==events[0]]\n",
    "df_eq1 = record_df[record_df['Earthquake ID']==events[1]]\n",
    "df_eq2 = record_df[record_df['Earthquake ID']==events[2]]\n",
    "df_eq3 = record_df[record_df['Earthquake ID']==events[3]]\n",
    "df_eq4 = record_df[record_df['Earthquake ID']==events[4]]\n",
    "df_eq5 = record_df[record_df['Earthquake ID']==events[5]]\n",
    "df_eq6 = record_df[record_df['Earthquake ID']==events[6]]\n",
    "df_eq7 = record_df[record_df['Earthquake ID']==events[7]]\n",
    "df_eq8 = record_df[record_df['Earthquake ID']==events[8]]\n",
    "df_eq9 = record_df[record_df['Earthquake ID']==events[9]]\n",
    "df_eq10 = record_df[record_df['Earthquake ID']==events[10]]\n",
    "                     \n",
    "earthquake_records = ['df_eq0', 'df_eq1', 'df_eq2', 'df_eq3', 'df_eq4', 'df_eq5', \n",
    "                      'df_eq6', 'df_eq7', 'df_eq8', 'df_eq9', 'df_eq10']\n",
    "\n",
    "parameters = ['Carbon monoxide', 'Nitrogen dioxide (NO2)', 'Ozone', \n",
    "              'PM10 Total 0-10um STP', 'PM2.5 - Local Conditions', 'Sulfur dioxide']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordgroupby_df = record_df.groupby(['Earthquake ID','Parameter','Date'])\n",
    "\n",
    "# giant_pivot = pd.pivot_table(recordgroupby_df, values=['Measurement'],columns = ['Parameter'], index = ['Earthquake ID','Date'])\n",
    "\n",
    "#giant#_pivot = pd.pivot_table(recordgroupby_df, values=['Measurement'],columns = ['Parameter'], index = ['Earthquake ID','Date'])\n",
    "\n",
    "\n",
    "# giant_pivot.to_csv('GiantPivot.csv')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#giant_pivot\n",
    "recordgroupby_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skinny_df = recordgroupby_df['Earthquake ID','Parameter','Date','Measurement']\n",
    "skinny_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events = [\"ci37908735\",\"nc72737985\",\"ci37374687\",\"nc72282711\",\"ci15200401\",\"ci15199681\",\"ci10736069\",\n",
    "          \"ci14408052\",\"ci14383980\",\"nc40216664\",\"nc40204628\"]\n",
    "\n",
    "parameters = ['Carbon monoxide', 'Nitrogen dioxide (NO2)', 'Ozone', \n",
    "              'PM10 Total 0-10um STP', 'PM2.5 - Local Conditions', 'Sulfur dioxide']\n",
    "\n",
    "earthquake = 0\n",
    "parameter = 2\n",
    "event = 'ci10736069'\n",
    "\n",
    "epochtime = earthquakes_df.iloc[earthquake, 13]\n",
    "aqi_event_date = time.strftime('%Y-%m-%d',  time.gmtime(epochtime/1000))\n",
    "earthquake_location=earthquakes_df.iloc[earthquake,2]\n",
    "earthquake_id = earthquakes_df.iloc[earthquake, 1]\n",
    "\n",
    "y_values = record_df[record_df['Parameter']=='Carbon monoxide']\n",
    "y_values = y_values[y_values['Earthquake ID']==events[6]]\n",
    "y_values = y_values[y_values['Station']=='0005']\n",
    "y_values = y_values[['Date','Measurement']].sort_values('Date')\n",
    "# y_values = y_values[y_values['Date','Measurement']]\n",
    "\n",
    "\n",
    "#df_eq0 = record_df[record_df['Earthquake ID']==events[0]]\n",
    "\n",
    "#x_values = giant_pivot.loc[['ci10736069','Date']].tolist()\n",
    "\n",
    "y_values\n",
    "\n",
    "# plt.plot(record_NO2['Date'],record_NO2['Measurement'])\n",
    "# plt.title('{0}'.format(\"NO2:\" + earthquake_location + \" \" + aqi_event_date), fontsize =30)\n",
    "# plt.xlabel(\"Date\", fontsize = 18)\n",
    "# plt.ylabel(\"NO2 (parts per billion)\", fontsize =18)\n",
    "# plt.rcParams[\"figure.figsize\"] = [16,8]\n",
    "# plt.rcParams['xtick.labelsize']=11\n",
    "# plt.rcParams['ytick.labelsize']=16\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.axvline(x=aqi_event_date, color='r', linewidth=4)\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_grouped = y_values.groupby(['Date']).mean()\n",
    "y_values_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_grouped.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
